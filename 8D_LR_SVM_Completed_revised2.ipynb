{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "86Tvnj5UblTy"
   },
   "source": [
    "## Task-D: Collinear features and their effect on linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qn_eOn2EblT3"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VMoYWIayblUB"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('task_d.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RfStXG4tblUI",
    "outputId": "ddf4eec6-7f53-4d28-914f-23133957d6d5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>x*x</th>\n",
       "      <th>2*y</th>\n",
       "      <th>2*z+3*x*x</th>\n",
       "      <th>w</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.581066</td>\n",
       "      <td>0.841837</td>\n",
       "      <td>-1.012978</td>\n",
       "      <td>-0.604025</td>\n",
       "      <td>0.841837</td>\n",
       "      <td>-0.665927</td>\n",
       "      <td>-0.536277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.894309</td>\n",
       "      <td>-0.207835</td>\n",
       "      <td>-1.012978</td>\n",
       "      <td>-0.883052</td>\n",
       "      <td>-0.207835</td>\n",
       "      <td>-0.917054</td>\n",
       "      <td>-0.522364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.207552</td>\n",
       "      <td>0.212034</td>\n",
       "      <td>-1.082312</td>\n",
       "      <td>-1.150918</td>\n",
       "      <td>0.212034</td>\n",
       "      <td>-1.166507</td>\n",
       "      <td>0.205738</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.364174</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>-0.943643</td>\n",
       "      <td>-1.280666</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>-1.266540</td>\n",
       "      <td>-0.665720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.737687</td>\n",
       "      <td>1.051772</td>\n",
       "      <td>-1.012978</td>\n",
       "      <td>-0.744934</td>\n",
       "      <td>1.051772</td>\n",
       "      <td>-0.792746</td>\n",
       "      <td>-0.735054</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y         z       x*x       2*y  2*z+3*x*x         w  \\\n",
       "0 -0.581066  0.841837 -1.012978 -0.604025  0.841837  -0.665927 -0.536277   \n",
       "1 -0.894309 -0.207835 -1.012978 -0.883052 -0.207835  -0.917054 -0.522364   \n",
       "2 -1.207552  0.212034 -1.082312 -1.150918  0.212034  -1.166507  0.205738   \n",
       "3 -1.364174  0.002099 -0.943643 -1.280666  0.002099  -1.266540 -0.665720   \n",
       "4 -0.737687  1.051772 -1.012978 -0.744934  1.051772  -0.792746 -0.735054   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JIIuomCkblUP"
   },
   "outputs": [],
   "source": [
    "X = data.drop(['target'], axis=1).values\n",
    "Y = data['target'].values\n",
    "feature_mapping = {1:'x',2:'y',3:'z',4:'x*x',5:'2*y',6:'2*z+3*x*x',7:'w'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 7)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "#print(X[1:10])\n",
    "#print((X+100)[1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ydm98u3EblUU"
   },
   "source": [
    "### Doing perturbation test to check the presence of collinearity  \n",
    "\n",
    "#### Task: 1 Logistic Regression\n",
    "<pre>\n",
    "\n",
    "\n",
    "1. <b>Finding the Correlation between the features</b>\n",
    "    a. check the correlation between the features\n",
    "    b. plot heat map of correlation matrix using seaborn heatmap\n",
    "2. <b>Finding the best model for the given data</b>\n",
    "    a. Train Logistic regression on data(X,Y) that we have created in the above cell\n",
    "    b. Find the best hyper prameter alpha with hyper parameter tuning using k-fold cross validation (grid search CV or         \n",
    "    random search CV make sure you choose the alpha in log space)\n",
    "    c. Creat a new Logistic regression with the best alpha\n",
    "    (search for how to get the best hyper parameter value), name the best model as 'best_model'\n",
    "    \n",
    "3. <b>Getting the weights with the original data</b>\n",
    "    a. train the 'best_model' with X, Y\n",
    "    b. Check the accuracy of the model 'best_model_accuracy'\n",
    "    c. Get the weights W using best_model.coef_\n",
    "\n",
    "4. <b>Modifying original data</b>\n",
    "    a. Add a noise(order of 10^-2) to each element of X \n",
    "    and get the new data set X' (X' = X + e)\n",
    "    b. Train the same 'best_model' with data (X', Y)\n",
    "    c. Check the accuracy of the model 'best_model_accuracy_edited'\n",
    "    d. Get the weights W' using best_model.coef_\n",
    "    \n",
    "5. <b> Checking deviations in metric and weights </b>\n",
    "    a. find the difference between 'best_model_accuracy_edited' and 'best_model_accuracy'\n",
    "    b. find the absolute change between each value of W and W' ==> |(W-W')|\n",
    "    c. print the top 4 features which have higher % change in weights \n",
    "    compare to the other feature\n",
    "\n",
    "</pre>\n",
    "\n",
    "#### Task: 2 Linear SVM\n",
    "\n",
    "<pre>\n",
    "1. Do the same steps (2, 3, 4, 5) we have done in the above task 1.\n",
    "</pre>\n",
    "\n",
    "<strong><font color='red'>Do write the observations based on the results you get from the deviations of weights in both Logistic Regression and linear SVM</font></strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lai8wXU1pmSb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************Heat Map of correlation between feature***********************\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Doing perturbation test to check the presence of collinearity\n",
    "#Task: 1 Logistic Regression\n",
    "\n",
    "#Finding the Correlation between the features via Pearson Correlation Cofficient \n",
    "correlation_coef = np.corrcoef(X,rowvar=False)\n",
    "#print(correlation_coef.shape)\n",
    "#print(correlation_coef)\n",
    "\n",
    "#Adding column names, row names for more readability \n",
    "df = pd.DataFrame(correlation_coef,columns=[\"F1\",\"F2\",\"F3\",\"F4\",\"F5\",\"F6\",\"F7\"],index = [\"F1\",\"F2\",\"F3\",\"F4\",\"F5\",\"F6\",\"F7\"])\n",
    "#print(df)\n",
    "print(\"***************Heat Map of correlation between feature***********************\")\n",
    "ax =sns.heatmap(df,annot = True, xticklabels=True, yticklabels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********Best Estimator********\n",
      "SGDClassifier(alpha=0.01, loss='log', random_state=20)\n",
      "{'alpha': 0.01}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.01, loss='log', random_state=20)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the best model for the given data\n",
    "#Train Logistic regression on data(X,Y) that we have created in the above cell\n",
    "logistic_regression = SGDClassifier(loss='log',random_state = 20)\n",
    "logistic_regression.fit(X,Y)\n",
    "\n",
    "#Find the best hyper prameter alpha with hyper parameter tuning using k-fold cross validation (grid search CV or random search CV make sure you choose the alpha in log space)\n",
    "parameters = {'alpha':[0.0001,0.001,0.01,0.1,1, 10,100,1000,10000]}\n",
    "clf = GridSearchCV(logistic_regression, parameters)\n",
    "clf.fit(X,Y)\n",
    "#print(clf.cv_results_)\n",
    "print(\"********Best Estimator********\")\n",
    "best_alpha = clf.best_params_['alpha']\n",
    "print(clf.best_estimator_)\n",
    "print(clf.best_params_)\n",
    "#print(clf.cv_results_)\n",
    "\n",
    "#Creat a new Logistic regression with the best alpha (search for how to get the best hyper parameter value), name the best model as 'best_model'\n",
    "best_model = SGDClassifier(loss = 'log',alpha = best_alpha,random_state =20)\n",
    "best_model.fit(X,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Accuracy:  1.0\n",
      "Best Model's Class Weights:  [ 0.726548   -0.89728841  1.72389953  0.66247604 -0.89728841  0.80436469\n",
      "  0.50135355]\n"
     ]
    }
   ],
   "source": [
    "#Getting the weights with the original data\n",
    "#Check the accuracy of the model 'best_model_accuracy'\n",
    "class_weights = best_model.coef_[0]\n",
    "best_model_accuracy = best_model.score(X,Y)\n",
    "print(\"Best Model Accuracy: \", best_model_accuracy)\n",
    "\n",
    "#Get the weights W using best_model.coef_\n",
    "print(\"Best Model's Class Weights: \", class_weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X before Pertuberation:\n",
      "[[-0.5810659   0.84183714 -1.01297765 -0.60402468  0.84183714 -0.66592679\n",
      "  -0.53627703]]\n",
      "X after Pertuberation:\n",
      "[[-0.5710659   0.85183714 -1.00297765 -0.59402468  0.85183714 -0.65592679\n",
      "  -0.52627703]]\n",
      "*******************************************************************************************\n",
      "Best Model Accuracy After Pertuberation:  1.0\n",
      "Best Model's Class Weights:  [ 0.72665047 -0.89716276  1.72336461  0.66294523 -0.89716276  0.80469158\n",
      "  0.50207115]\n"
     ]
    }
   ],
   "source": [
    "#Modifying original data\n",
    "#Add a noise(order of 10^-2) to each element of X and get the new data set X' (X' = X + e)\n",
    "e = 0.01\n",
    "print(\"X before Pertuberation:\")\n",
    "print(X[0:1])\n",
    "X = X+e\n",
    "print(\"X after Pertuberation:\")\n",
    "print(X[0:1])\n",
    "\n",
    "#Train the same 'best_model' with data (X', Y)\n",
    "best_model.fit(X,Y)\n",
    "\n",
    "#Check the accuracy of the model 'best_model_accuracy_edited'\n",
    "print(\"*******************************************************************************************\")\n",
    "best_model_accuracy_edited = best_model.score(X,Y)\n",
    "print(\"Best Model Accuracy After Pertuberation: \", best_model_accuracy_edited)\n",
    "\n",
    "#Get the weights W' using best_model.coef_\n",
    "class_weights_edited = best_model.coef_[0]\n",
    "print(\"Best Model's Class Weights: \", class_weights_edited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "difference between 'best_model_accuracy_edited' and 'best_model_accuracy':  0.0\n",
      "Absolute change between each value of W and W':  [0.00010247 0.00012565 0.00053492 0.0004692  0.00012565 0.00032689\n",
      " 0.0007176 ]\n",
      "class_weigths_difference_pct:  [0.00014103 0.00014003 0.0003103  0.00070825 0.00014003 0.00040639\n",
      " 0.00143133]\n",
      "***********************************************************************************************\n",
      "Top 4 features which have higher % change in weights compare to the other feature ['w', 'x*x', '2*z+3*x*x', 'z']\n"
     ]
    }
   ],
   "source": [
    "# Checking deviations in metric and weights \n",
    "# find the difference between 'best_model_accuracy_edited' and 'best_model_accuracy'\n",
    "accuracy_difference = (best_model_accuracy_edited-best_model_accuracy)\n",
    "print(\"difference between 'best_model_accuracy_edited' and 'best_model_accuracy': \",accuracy_difference)\n",
    "\n",
    "# find the absolute change between each value of W and W' ==> |(W-W')|\n",
    "class_weigths_difference = abs(class_weights - class_weights_edited)\n",
    "print(\"Absolute change between each value of W and W': \",class_weigths_difference)\n",
    "\n",
    "# print the top 4 features which have higher % change in weights compare to the other feature\n",
    "class_weigths_difference_pct_logistic = abs((class_weights - class_weights_edited) / class_weights)\n",
    "print(\"class_weigths_difference_pct: \", class_weigths_difference_pct_logistic)\n",
    "#print(np.argsort(class_weigths_difference_pct))\n",
    "print(\"***********************************************************************************************\")\n",
    "#print(np.argsort(class_weigths_difference_pct)[:2:-1])\n",
    "\n",
    "print(\"Top 4 features which have higher % change in weights compare to the other feature\",[feature_mapping[i+1] for i in (np.argsort(class_weigths_difference_pct_logistic)[:2:-1])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********Best Estimator********\n",
      "SGDClassifier(alpha=0.1, random_state=20)\n",
      "{'alpha': 0.1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.1, loss='log', random_state=20)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#***************Perform Steps 2 to 5 with SVM*******************\n",
    "#Finding the best model for the given data\n",
    "#Train svm on data(X,Y) that we have created in the above cell\n",
    "svm = SGDClassifier(loss='hinge',random_state =20)\n",
    "svm.fit(X,Y)\n",
    "\n",
    "#Find the best hyper prameter alpha with hyper parameter tuning using k-fold cross validation (grid search CV or random search CV make sure you choose the alpha in log space)\n",
    "parameters = {'alpha':[0.0001,0.001,0.01,0.1,1, 10,100,1000,10000]}\n",
    "clf = GridSearchCV(svm, parameters)\n",
    "clf.fit(X,Y)\n",
    "#print(clf.cv_results_)\n",
    "print(\"********Best Estimator********\")\n",
    "best_alpha = clf.best_params_['alpha']\n",
    "print(clf.best_estimator_)\n",
    "print(clf.best_params_)\n",
    "#print(clf.cv_results_)\n",
    "\n",
    "#Creat a new svm with the best alpha (search for how to get the best hyper parameter value), name the best model as 'best_model'\n",
    "best_model = SGDClassifier(loss = 'log',alpha = best_alpha,random_state = 20)\n",
    "best_model.fit(X,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Accuracy:  1.0\n",
      "Best Model's Class Weights:  [ 0.4078346  -0.52117395  0.79424456  0.38563394 -0.52117395  0.4429374\n",
      "  0.34597669]\n"
     ]
    }
   ],
   "source": [
    "#Getting the weights with the original data\n",
    "#Check the accuracy of the model 'best_model_accuracy'\n",
    "class_weights = best_model.coef_[0]\n",
    "best_model_accuracy = best_model.score(X,Y)\n",
    "print(\"Best Model Accuracy: \", best_model_accuracy)\n",
    "\n",
    "#Get the weights W using best_model.coef_\n",
    "print(\"Best Model's Class Weights: \", class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X before Pertuberation:\n",
      "[[-0.5710659   0.85183714 -1.00297765 -0.59402468  0.85183714 -0.65592679\n",
      "  -0.52627703]]\n",
      "X after Pertuberation:\n",
      "[[-0.5610659   0.86183714 -0.99297765 -0.58402468  0.86183714 -0.64592679\n",
      "  -0.51627703]]\n",
      "*******************************************************************************************\n",
      "Best Model Accuracy After Pertuberation:  1.0\n",
      "Best Model's Class Weights:  [ 0.40800789 -0.52064558  0.79465013  0.3858671  -0.52064558  0.44316916\n",
      "  0.34658003]\n"
     ]
    }
   ],
   "source": [
    "#Modifying original data\n",
    "#Add a noise(order of 10^-2) to each element of X and get the new data set X' (X' = X + e)\n",
    "e = 0.01\n",
    "print(\"X before Pertuberation:\")\n",
    "print(X[0:1])\n",
    "X = X+e\n",
    "print(\"X after Pertuberation:\")\n",
    "print(X[0:1])\n",
    "\n",
    "#Train the same 'best_model' with data (X', Y)\n",
    "best_model.fit(X,Y)\n",
    "\n",
    "#Check the accuracy of the model 'best_model_accuracy_edited'\n",
    "print(\"*******************************************************************************************\")\n",
    "best_model_accuracy_edited = best_model.score(X,Y)\n",
    "print(\"Best Model Accuracy After Pertuberation: \", best_model_accuracy_edited)\n",
    "\n",
    "#Get the weights W' using best_model.coef_\n",
    "class_weights_edited = best_model.coef_[0]\n",
    "print(\"Best Model's Class Weights: \", class_weights_edited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "difference between 'best_model_accuracy_edited' and 'best_model_accuracy':  0.0\n",
      "Absolute change between each value of W and W':  [0.00017328 0.00052838 0.00040557 0.00023316 0.00052838 0.00023176\n",
      " 0.00060334]\n",
      "class_weigths_difference_pct:  [0.00042488 0.00101382 0.00051063 0.00060461 0.00101382 0.00052324\n",
      " 0.00174387]\n",
      "***********************************************************************************************\n",
      "Top 4 features which have higher % change in weights compare to the other feature ['w', '2*y', 'y', 'x*x']\n"
     ]
    }
   ],
   "source": [
    "# Checking deviations in metric and weights \n",
    "# find the difference between 'best_model_accuracy_edited' and 'best_model_accuracy'\n",
    "accuracy_difference = (best_model_accuracy_edited-best_model_accuracy)\n",
    "print(\"difference between 'best_model_accuracy_edited' and 'best_model_accuracy': \",accuracy_difference)\n",
    "\n",
    "# find the absolute change between each value of W and W' ==> |(W-W')|\n",
    "class_weigths_difference = abs(class_weights - class_weights_edited)\n",
    "print(\"Absolute change between each value of W and W': \",class_weigths_difference)\n",
    "\n",
    "# print the top 4 features which have higher % change in weights compare to the other feature\n",
    "class_weigths_difference_pct_svm = abs((class_weights - class_weights_edited) / class_weights)\n",
    "print(\"class_weigths_difference_pct: \", class_weigths_difference_pct_svm)\n",
    "#print(np.argsort(class_weigths_difference_pct))\n",
    "print(\"***********************************************************************************************\")\n",
    "#print(np.argsort(class_weigths_difference_pct)[:2:-1])\n",
    "\n",
    "print(\"Top 4 features which have higher % change in weights compare to the other feature\",[feature_mapping[i+1] for i in (np.argsort(class_weigths_difference_pct_svm)[:2:-1])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "class_weigths_difference_pct via logistic:  [0.00014103 0.00014003 0.0003103  0.00070825 0.00014003 0.00040639\n",
      " 0.00143133]\n",
      "----------------------------------------------------------------------\n",
      "class_weigths_difference_pct via SVM:  [0.00042488 0.00101382 0.00051063 0.00060461 0.00101382 0.00052324\n",
      " 0.00174387]\n",
      "No differnce in class_weigths_difference_pct via logistic and SVM \n",
      "----------------------------------------------------------------------\n",
      "Top 4 features which have higher % change in weights in both cases [SVM] and [Logistic Regression] ['w', '2*y', 'y', 'x*x']\n"
     ]
    }
   ],
   "source": [
    " #Print the top 4 feature names explicitly having the highest percentage change in both the tasks.\n",
    "\n",
    "print(\"-\"*70)\n",
    "print(\"class_weigths_difference_pct via logistic: \", class_weigths_difference_pct_logistic)\n",
    "print(\"-\"*70)\n",
    "print(\"class_weigths_difference_pct via SVM: \", class_weigths_difference_pct_svm)\n",
    "print(\"No differnce in class_weigths_difference_pct via logistic and SVM \")\n",
    "print(\"-\"*70)\n",
    "print(\"Top 4 features which have higher % change in weights in both cases [SVM] and [Logistic Regression]\",[feature_mapping[i+1] for i in (np.argsort(class_weigths_difference_pct_svm)[:2:-1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation:\n",
    "- Mean deviation of class weights for logistic regression: 0.1177683 \n",
    "- Mean deviation of class weights for SVM: 0.037347999\n",
    "- Therefore, SVM has less deviation and more robust to pertuberation of train data. \n",
    "- And, Feature 7 is more important in classification irrespective of algorithm selected.\n",
    "- Top 4 features which have higher % change in weights in both cases [SVM] and [Logistic Regression] ['w', '2*y', 'y', 'x*x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "8D_LR_SVM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
